#!/usr/bin/env python3
"""
M5 Veri Seti KÃ¼Ã§Ã¼k Ã‡alÄ±ÅŸma Seti Ãœretici

Bu script M5 veri setinden kÃ¼Ã§Ã¼k bir alt-kÃ¼me oluÅŸturur:
- CA eyaleti, CA_1 maÄŸazasÄ±, FOODS kategorisi
- En yÃ¼ksek satÄ±ÅŸlÄ± 5 Ã¼rÃ¼n
- GÃ¼nlÃ¼k zaman serisi formatÄ±nda
- Train/Validation split (son 28 gÃ¼n validation)

KullanÄ±m: python create_m5_subset.py
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
from datetime import datetime

def create_m5_subset():
    """M5 veri setinden kÃ¼Ã§Ã¼k Ã§alÄ±ÅŸma seti oluÅŸtur"""
    
    print("ğŸ¯ M5 KÃ¼Ã§Ã¼k Ã‡alÄ±ÅŸma Seti OluÅŸturucu")
    print("=" * 50)
    
    # Ã‡Ä±ktÄ± klasÃ¶rlerini oluÅŸtur
    os.makedirs('./artifacts/datasets', exist_ok=True)
    os.makedirs('./artifacts/figures', exist_ok=True)
    
    # 1. Veri dosyalarÄ±nÄ± oku
    print("\nğŸ“ 1. Veri dosyalarÄ± okunuyor...")
    
    try:
        # Sales verisi
        print("   â€¢ sales_train_validation.csv okunuyor...")
        sales_df = pd.read_csv('/Users/eyyupcap/Desktop/AyÅŸe/VS Code/Kairu_DS360/Week_5/data/sales_train_validation.csv')
        print(f"   âœ“ SatÄ±ÅŸ verisi: {sales_df.shape}")
        
        # Calendar verisi
        print("   â€¢ calendar.csv okunuyor...")
        calendar_df = pd.read_csv('/Users/eyyupcap/Desktop/AyÅŸe/VS Code/Kairu_DS360/Week_5/data/calendar.csv')
        calendar_df['date'] = pd.to_datetime(calendar_df['date'])
        print(f"   âœ“ Takvim verisi: {calendar_df.shape}")
        
        # Prices verisi (opsiyonel, kullanmayacaÄŸÄ±z ama kontrol edelim)
        try:
            prices_df = pd.read_csv('/Users/eyyupcap/Desktop/AyÅŸe/VS Code/Kairu_DS360/Week_5/data/sell_prices.csv')
            print(f"   âœ“ Fiyat verisi: {prices_df.shape}")
        except FileNotFoundError:
            print("   âš ï¸  Fiyat verisi bulunamadÄ± (isteÄŸe baÄŸlÄ±)")
            
    except FileNotFoundError as e:
        print(f"   âŒ Veri dosyasÄ± bulunamadÄ±: {e}")
        print("   ğŸ’¡ Ã–nce create_sample_data.py Ã§alÄ±ÅŸtÄ±rÄ±n veya gerÃ§ek M5 verisini indirin")
        return None, None, None
    
    # 2. CA_1 maÄŸazasÄ± ve FOODS kategorisini filtrele
    print("\nğŸª 2. CA_1 maÄŸazasÄ± ve FOODS kategorisi filtreleniyor...")
    
    # CA_1 maÄŸazasÄ± filtresi
    ca1_mask = (sales_df['store_id'] == 'CA_1')
    ca1_sales = sales_df[ca1_mask].copy()
    print(f"   â€¢ CA_1 maÄŸazasÄ± Ã¼rÃ¼n sayÄ±sÄ±: {len(ca1_sales)}")
    
    # FOODS kategorisi filtresi
    # M5'te kategori 'cat_id' sÃ¼tununda, FOODS genelde FOODS ile baÅŸlar
    foods_mask = ca1_sales['cat_id'].str.contains('FOOD', case=False, na=False)
    foods_sales = ca1_sales[foods_mask].copy()
    print(f"   â€¢ FOODS kategorisi Ã¼rÃ¼n sayÄ±sÄ±: {len(foods_sales)}")
    
    if len(foods_sales) == 0:
        print("   âš ï¸  FOODS kategorisi bulunamadÄ±, tÃ¼m kategorileri kullanÄ±yoruz...")
        foods_sales = ca1_sales.copy()
    
        # 3. Veriyi gÃ¼nlÃ¼k formata dÃ¶nÃ¼ÅŸtÃ¼r ve en yÃ¼ksek satÄ±ÅŸlÄ± 5 Ã¼rÃ¼nÃ¼ bul
    print("\nğŸ“Š 3. Veriler gÃ¼nlÃ¼k formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
    
    # SatÄ±ÅŸ verilerini uzun formata dÃ¶nÃ¼ÅŸtÃ¼r
    id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']
    sales_long = pd.melt(foods_sales, 
                        id_vars=id_vars,
                        var_name='d', 
                        value_name='sales')
    
    # d_1, d_2 gibi sÃ¼tunlarÄ± takvim ile eÅŸleÅŸtir
    sales_long = sales_long.merge(calendar_df[['d', 'date']], on='d', how='left')
    
    # En yÃ¼ksek satÄ±ÅŸlÄ± 5 Ã¼rÃ¼nÃ¼ bul
    total_sales_by_item = sales_long.groupby('item_id')['sales'].sum().sort_values(ascending=False)
    top_5_items = total_sales_by_item.head(5).index.tolist()
    print(f"   â€¢ En Ã§ok satÄ±lan 5 Ã¼rÃ¼n: {', '.join(top_5_items)}")
    
    # Sadece en yÃ¼ksek satÄ±ÅŸlÄ± 5 Ã¼rÃ¼nÃ¼ filtrele
    top_sales = sales_long[sales_long['item_id'].isin(top_5_items)].copy()
    
    # 4. Veriyi temizle ve hazÄ±rla
    print("\nğŸ§¹ 4. Veriler dÃ¼zenleniyor...")
    
    # GÃ¼nlÃ¼k zaman serisi formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
    complete_df = top_sales[['date', 'item_id', 'sales']].copy()
    
    # TÃ¼m olasÄ± tarih-Ã¼rÃ¼n kombinasyonlarÄ±nÄ± oluÅŸtur
    all_dates = calendar_df['date'].unique()
    all_dates_sorted = sorted(all_dates)
    
    # Train/validation split iÃ§in tarihler
    split_date = all_dates_sorted[-28]  # Son 28 gÃ¼n validation
    train_end_date = all_dates_sorted[-29]  # Train sonu
    
    print(f"   â€¢ Toplam {len(all_dates_sorted)} gÃ¼n, split tarihi: {split_date.strftime('%Y-%m-%d')}")
    
    # 5. Train ve validation setlerini oluÅŸtur
    print("\nğŸ”„ 5. Train ve validation setleri oluÅŸturuluyor...")
    
    # Train ve validation setleri
    train_df = complete_df[complete_df['date'] <= train_end_date].copy()
    valid_df = complete_df[complete_df['date'] >= split_date].copy()
    
    print(f"   â€¢ Train: {train_df['date'].min()} - {train_df['date'].max()} ({len(train_df)} satÄ±r)")
    print(f"   â€¢ Valid: {valid_df['date'].min()} - {valid_df['date'].max()} ({len(valid_df)} satÄ±r)")
    
    # Index'i tarih yap
    train_df = train_df.set_index('date')
    valid_df = valid_df.set_index('date')
    
    # 7. Ã‡Ä±ktÄ±larÄ± kaydet
    print("\nğŸ’¾ 6. SonuÃ§lar kaydediliyor...")
    
    # CSV dosyalarÄ±
    train_path = './artifacts/datasets/train.csv'
    valid_path = './artifacts/datasets/valid.csv'
    
    train_df.to_csv(train_path)
    valid_df.to_csv(valid_path)
    
    print(f"   âœ“ Train verisi: {train_path}")
    print(f"   âœ“ Valid verisi: {valid_path}")
    
    # 8. GÃ¶rselleÅŸtirme
    print("\nğŸ“Š 7. GÃ¼nlÃ¼k toplam satÄ±ÅŸ grafiÄŸi oluÅŸturuluyor...")
    
    # GÃ¼nlÃ¼k toplam satÄ±ÅŸ hesapla
    daily_total = complete_df.groupby('date')['sales'].sum().reset_index()
    
    # Grafik oluÅŸtur
    plt.figure(figsize=(15, 8))
    
    # Train ve validation bÃ¶lgelerini ayÄ±r
    train_dates = train_df.reset_index()['date'].unique()
    valid_dates = valid_df.reset_index()['date'].unique()
    
    train_total = daily_total[daily_total['date'].isin(train_dates)]
    valid_total = daily_total[daily_total['date'].isin(valid_dates)]
    
    # Train verisi
    plt.plot(train_total['date'], train_total['sales'], 
             label='Train', color='blue', linewidth=2)
    
    # Validation verisi
    plt.plot(valid_total['date'], valid_total['sales'], 
             label='Validation', color='red', linewidth=2)
    
    # Split Ã§izgisi
    plt.axvline(x=split_date, color='gray', linestyle='--', alpha=0.7, 
                label=f'Train/Valid Split ({split_date.strftime("%Y-%m-%d")})')
    
    # Grafik dÃ¼zenlemeleri
    plt.title('M5 SeÃ§ilen 5 ÃœrÃ¼n - GÃ¼nlÃ¼k Toplam SatÄ±ÅŸ\n' + 
              f'CA_1 MaÄŸazasÄ±, FOODS Kategorisi', fontsize=16, fontweight='bold')
    plt.xlabel('Tarih', fontsize=12)
    plt.ylabel('GÃ¼nlÃ¼k Toplam SatÄ±ÅŸ', fontsize=12)
    plt.legend(fontsize=12)
    plt.grid(True, alpha=0.3)
    
    # X ekseni etiketlerini dÃ¶ndÃ¼r
    plt.xticks(rotation=45)
    
    # Layout ayarla
    plt.tight_layout()
    
    # Kaydet
    figure_path = './artifacts/figures/overall_daily_sales.png'
    plt.savefig(figure_path, dpi=300, bbox_inches='tight')
    print(f"   âœ“ Grafik: {figure_path}")
    
    plt.close()
    
    # 9. Ã–zet bilgiler
    print("\nğŸ“‹ Ã–ZET BÄ°LGÄ°LER")
    print("=" * 50)
    print(f"â€¢ SeÃ§ilen Ã¼rÃ¼nler: {', '.join(complete_df['item_id'].unique())}")
    print(f"â€¢ Toplam gÃ¼n sayÄ±sÄ±: {len(all_dates_sorted)}")
    print(f"â€¢ Train gÃ¼n sayÄ±sÄ±: {len(train_df.reset_index()['date'].unique())}")
    print(f"â€¢ Validation gÃ¼n sayÄ±sÄ±: {len(valid_df.reset_index()['date'].unique())}")
    print(f"â€¢ Ortalama gÃ¼nlÃ¼k satÄ±ÅŸ: {daily_total['sales'].mean():.1f}")
    print(f"â€¢ Maksimum gÃ¼nlÃ¼k satÄ±ÅŸ: {daily_total['sales'].max()}")
    print(f"â€¢ Minimum gÃ¼nlÃ¼k satÄ±ÅŸ: {daily_total['sales'].min()}")
    
    # ÃœrÃ¼n bazÄ±nda istatistikler
    print(f"\nğŸ“Š ÃœRÃœN BAZINDA Ä°STATÄ°STÄ°KLER:")
    item_stats = complete_df.groupby('item_id')['sales'].agg(['sum', 'mean', 'std', 'max']).round(2)
    for item_id, stats in item_stats.iterrows():
        print(f"â€¢ {item_id}: Toplam={stats['sum']:,.0f}, Ort={stats['mean']:.1f}, "
              f"Std={stats['std']:.1f}, Max={stats['max']:.0f}")
    
    print(f"\nâœ… Ä°ÅŸlem tamamlandÄ±!")
    print(f"ğŸ“ Ã‡Ä±ktÄ±lar: ./artifacts/ klasÃ¶rÃ¼nde")
    
    return train_df, valid_df, daily_total

def main():
    """run_modular.py iÃ§in wrapper fonksiyonu"""
    result = create_m5_subset()
    if result is None or (isinstance(result, tuple) and result[0] is None):
        print(f"âŒ Veri dosyasÄ± bulunamadÄ±. Sample data kullanÄ±n.")
        return False
    else:
        print(f"âœ… M5 CA_1 FOODS subset created successfully!")
        return True

if __name__ == "__main__":
    try:
        result = create_m5_subset()
        if result is None or (isinstance(result, tuple) and result[0] is None):
            print(f"\nâŒ Veri dosyasÄ± bulunamadÄ±. Script durduruluyor.")
        else:
            train_data, valid_data, daily_sales = result
            print(f"\nğŸ‰ M5 kÃ¼Ã§Ã¼k Ã§alÄ±ÅŸma seti baÅŸarÄ±yla oluÅŸturuldu!")
        
    except Exception as e:
        print(f"\nâŒ Hata: {e}")
        import traceback
        traceback.print_exc()